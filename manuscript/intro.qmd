# Introduction {#intro}

What’s your biggest concern about using machine learning?
A survey [@vannoordenAIScienceWhat2023] asked 1600 scientists this question. “Leads to more reliance on pattern recognition without understanding” was the top concern.
But that lack of understanding is not unique to science.
Many data scientists and statisticians have told me that a reason they are using "simplear models" is that they wouldn't be able to convince their boss to use a "black box model" or there are regulatory reasons that make them uncertain.





Machine learning has received great attention from many people in research and industry.
Sometimes machine learning is overhyped in the media, but there are many real and impactful applications.
Machine learning is a powerful technology for products, research and automation.
Today, machine learning is used to detect fraudulent financial transactions, recommend movies and classify images.
It's often crucial that machine learning models are interpretable.
Interpretability helps developers with debugging and improvements, builds trust in the model, justifies model predictions and leads to new insights.
The increased need for machine learning interpretability is a natural consequence of an increased use of machine learning.

This book explains to you how to make (supervised) machine learning models interpretable.
The chapters contain some mathematical formulas, but you should be able to understand the ideas behind the methods even without the formulas.
This book is not for people trying to learn machine learning from scratch.
If you are new to machine learning, there are a lot of books and other resources to learn the basics.
I recommend the book ["The Elements of Statistical Learning" by Hastie, Tibshirani, and Friedman (2009)](https://hastie.su.domains/ElemStatLearn/) [@hastie2009elements] and [Andrew Ng's "Machine Learning" online course](https://www.coursera.org/learn/machine-learning)  on the online learning platform  coursera.com to start with machine learning.
Both the book and the course are available free of charge!

New methods for the interpretation of machine learning models are published at breakneck speed.
To keep up with everything that is published would be madness and simply impossible.
That is why you will not find the most novel and fancy methods in this book, but established methods and basic concepts of machine learning interpretability.
These basics prepare you for making machine learning models interpretable.
Internalizing the basic concepts also empowers you to better understand and evaluate any new paper on interpretability published on [arxiv.org](https://arxiv.org/) in the last 5 minutes since you began reading this book (I might be exaggerating the publication rate).

This book starts with some (dystopian) [short stories](#storytime) that are not needed to understand the book, but hopefully will entertain and make you think.
Then the book explores the concepts of [machine learning interpretability](#interpretability).
We will discuss when interpretability is important and the different types of explanations that exist.
Terms used throughout the book can be looked up in the [Terminology chapter](#terminology).
Most of the models and methods explained are presented using real data examples which are described in the [Data chapter](#data).
One way to make machine learning interpretable is to use [interpretable models](#simple), such as linear models or decision trees.
The other option is the use of [model-agnostic interpretation tools](#agnostic) that can be applied to any supervised machine learning model.
Model-agnostic methods can be divided into [global methods](#global-methods) that describe the average behavior of the model, and [local methods](#local-methods) that explain individual predictions.
The Model-Agnostic Methods chapter deals with methods such as [partial dependence plots](#pdp) and [feature importance](#feature-importance).
Model-agnostic methods work by changing the input of the machine learning model and measuring changes in the prediction output.
The book ends with an optimistic outlook on what [the future of interpretable machine learning](#future) might look like.




## How to read the book

You don't have to read the book cover from cover, but I know many people do.
Interpretable Machine Learning is almost a reference book, since most chapters describe one method.
If you are new to interpretability, I only would recommend reading the [Interpretability Chapter](#interpretability) and the [Methods Overview Chapter](#overview) first to understand what interpretability is all about and to have a "map" where you can place each method. 

The methods chapters all follow a similar structure:
The first paragraph summarizes the method, followed by an intuitive explanation that doesn't rely on math.
The we look into the theory of the method to get a deeper understanding of how it works, including math and algorithms.
I believe that a new method is best understood using examples.
Therefore, each method is applied to real data.
Some people say that statisticians are very critical people.
For me, this is true, because each chapter contains critical discussions about advantages and disadvantages of the respective interpretation method.
This book is not an advertisement for the methods, but it should help you decide whether a method works well for your application or not.
In the last section of each chapter, available software implementations are discussed.

I hope you will enjoy the read!
