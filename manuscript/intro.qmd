# Introduction {#intro}


<!-- need for interpretability -->
What’s your biggest concern about using machine learning?
A survey [@vannoordenAIScienceWhat2023] asked 1600 scientists this question. “Leads to more reliance on pattern recognition without understanding” was the top concern.
But that lack of understanding is not unique to science.
Many data scientists and statisticians have told me that a reason they are using "simplear models" is that they wouldn't be able to convince their boss to use a "black box model" or there are regulatory reasons that make them uncertain.
<!-- TODO: Add examples like Asthma, wolf vs dog, clever hans, etc. -->


<!-- solution: interpretability -->
Interpretability helps developers with debugging and improvements, builds trust in the model, justifies model predictions and leads to new insights.
The increased need for machine learning interpretability is a natural consequence of an increased use of machine learning.

<!-- TODO CONTINUE HERE WITH HISTORY OF IML ? -->


<!-- this book -->
New methods for the interpretation of machine learning models are published at breakneck speed.
To keep up with everything that is published would be madness and simply impossible.
That is why you will not find the most novel and fancy methods in this book, but established methods and basic concepts of machine learning interpretability.
These basics prepare you for making machine learning models interpretable.
Internalizing the basic concepts also empowers you to better understand and evaluate any new paper on interpretability published on [arxiv.org](https://arxiv.org/) in the last 5 minutes since you began reading this book (I might be exaggerating the publication rate).



## How to read the book

You don't have to read the book cover from cover, but I know many people do.
Interpretable Machine Learning is almost a reference book, since most chapters describe one method.
If you are new to interpretability, I only would recommend reading the [Interpretability Chapter](#interpretability) and the [Methods Overview Chapter](#overview) first to understand what interpretability is all about and to have a "map" where you can place each method. 

The book is organized into the following parts: 

- The introductory chapters, including interpretability definitions and methods overview 
- Interpretable models 
- Local model-agnostic methods
- Global model-agnostic methods
- Interpretation methods for neural networks
- Outlook part, including short stories, speculations about the future, and related fields.
- Appendices for terminology and explaining the datasets

The methods chapters in the various method parts follow a similar structure:
The first paragraph summarizes the method, followed by an intuitive explanation that doesn't rely on math.
The we look into the theory of the method to get a deeper understanding of how it works, including math and algorithms.
I believe that a new method is best understood using examples.
Therefore, each method is applied to real data.
Some people say that statisticians are very critical people.
For me, this is true, because each chapter contains critical discussions about advantages and disadvantages of the respective interpretation method.
This book is not an advertisement for the methods, but it should help you decide whether a method works well for your application or not.
In the last section of each chapter, available software implementations are discussed.

I hope you will enjoy the read!
