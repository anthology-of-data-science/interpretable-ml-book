# Ceterus Paribus Plots (what if analysis) {#what-if}

{{< include _setup.qmd >}}

Ceterus Paribus Plots [@kuzba2019pyceterisparibus] visualize how changes in a feature change the prediction of a data point.

TODO: cite ceteris paribus paper

<!-- introduction -->
This is really the simplest possible way to interpret the prediction of a data point: Change one of the features and see how the prediction changes.
We can learn from that how a feature influences the prediction of that data point, especially when we try a couple of values for that feature.
It's the equivalent of making funny faces towards a Gorilla in the zoo to create a reaction.
But really, why are we even talking about this simplistic approach?
There are three reasons:

- This simple approach done systematically, in the form of ceterus paribus profiles, can already give a lot of information about how the model makes predictions. And it is complementary to many other approaches, like SHAP.
- We can compare the ceterus paribus profiles across different models, features, and data points, so this "simple" analysis provides a surprising amount of depth.
- Changing a single feature is the prototype of model-agnostic methods. The cavemen painting that precedes modern art.

<!-- Ceteris Paribus algorithm -->
But anyways, let's get started with the "algorithm" ceteris paribus, if you want to call it that.
Wait, the name is Latin and means "other things equal".
I hate Latin, because I have been lied to in school.
They promised me that learning Latin helps with learning other Latin-based languages, like Italian.
But you no what even helps better when your goal is to learn Italian: That's right, you simply skip Latin and learn Italian.
Anyways, back to ceteris paribus.
Here is the algorithm:

1. Pick a data point to explain.
1. Pick a feature.
1. Create a grid of feature values and create new data points that are copies of the original data points but the feature value is replaced with the grid values.
1. Plot all the values as a line (for continuous feature) or dots (for categories) and highlight the current data points' value.

This recipe is rather simplistic, but really if we combine multiple of these lines (also called profiles), we can get a lot of insight.

Just some examples:

- Compare the profiles side-by-side for multiple features
- Within the same plot, you can compare the profiles for different models: Do different models work react differently to the what-ifs?
- If you have a binary feature, you can easily visualize the combination of both changing a binar features and a continuous feature in the same plot
- For multiclass you can show the lines in the same plot.
- You can compare a couple of data points in the same plot, but this already moves us in the direciton of an ICE plot and the lines are really blurred

It really is a versatile methjod for interpretability!

## Examples

Let's start with the regression example where we predict number of rented bikes based on weather and season with a random forest.
All plots are done with the ceterisParibus R package (there is also a Python version).
We pick one of the data points, namely January 1st 2011 and look at how changes in the features changes the predicted number of bike rentals.

```{r}
#| label: whatif-bike
#| fig-cap: "'How changing individual features changes the predicted number of bike rentals.'"
#| fig-height: 4
explainer_rf <- DALEX::explain(bike_rf, data = bike_test[colnames(bike) != "cnt"], y = bike_test$cnt, verbose=FALSE)

observation = bike_test[1,]

wi_rf <- ceteris_paribus(explainer_rf, observation = observation)
p = plot(wi_rf) +
  xlab("") +
  ylab("Predicted bike rentals")
p
```

We can see a bunch of things in this plot:
We can see how changes in each feature change the prediction, ranging from small changes to large changes and in all directions.
We can compare the features: For some features, like temperature, we can achieve strong changes in the prediction, while others, like humidity dont' achieve large changes.
Correlation between features is a concern (and ultimately the causality).
For example, increasing the temperature to 20 degrees Celsius from the 9 degrees would be rather unlikely temperature for January 1st in Washington.

As promised, these what-if scenarios are rather flexible and we can do a lot more with them:

For example, we can also compare how different models change their predictions on January 1st in reaction to feature changes.
For this I trained a random forest, a linear regression model and a single decision tree.
We only look at temperature here:

```{r whatif-bike-models, fig.cap='', fig.height = 4}
data_point =  bike[1,]

explainer_rf <- DALEX::explain(bike_rf, data = bike_test[colnames(bike) != "cnt"], y = bike_test$cnt, verbose=FALSE)
explainer_cart <- DALEX::explain(bike_tree, data = bike_test[colnames(bike) != "cnt"], y = bike_test$cnt, verbose=FALSE)
explainer_lm <- DALEX::explain(bike_lm, data = bike_test[colnames(bike) != "cnt"], y = bike_test$cnt, verbose=FALSE)
cp_rf = ceteris_paribus(explainer_rf, data_point, y = data_point$cnt)
cp_cart = ceteris_paribus(explainer_cart, data_point, y = data_point$cnt)
cp_lm = ceteris_paribus(explainer_lm, data_point, y = data_point$cnt)

p = plot(cp_rf, cp_cart, cp_lm, color = "_label_", selected_variables="temp", alpha=1) +
  xlab("Temperature in C") +
  ylab("Predicted bike rentals") +
  ggtitle("") +
  aes(linetype=`_label_`)
p
```

Here we can see how very different the models behave:
The linear model does what linear models do and model the relation linearly between temperature and predicted bike rentals.
The tree does not change the prediction for January 1st at all when changing the tempereature.
Teh random forest models an S-form relation between temperature and prediction with the steep part around 12 - 14 degrees Celsius.


For classification, plotting multiple lines at once, one for each class is also helpful to better understand how thue model work

For this example, we train a random forest to classify penguins into male versus female.
Let's the "What-If" for the probability when we change the bill length.
Simply done with the first penguin in the dataset, an Adelie penguin with a bill length of 39 millimeters.

```{r}
#| label: ceteris-penguins
#| fig-cap: Increasing the bill length from 35 decreases the chance of this penguin being Adelie, while the probability of Chinstrap increases. The probability of Gentoo remains flatly at zero.
pred2 <- function(m, x) predict(m, x, type = "prob")[,2]


data_point <- penguins_test[1,]
data_point_y = penguins_test[1,]$sex

explainer <- DALEX::explain(pengu_rf, data = penguins_test,
                              y = penguins_test$sex == "female",
			      predict_function = pred2, label = "female", verbose=FALSE)

cp_rf <- ceteris_paribus(explainer, data_point, y = data_point_y )
plot(cp_rf, color="_label_", selected_variables="bill_length_mm") +
  xlab("Bill length in mm") +
  ylab("P(female)")
```

## Connections to other interpretation methods

Ceterus paribus profiles are probably the simplest form of interpretability: We take one of the features and change it.
The only simpler version would be to just change it to a single value instead of trying out the entire feature range.

However, it connects to many other methods.

For starters, these ceteris paribus profiles are the building block for the feature effect methods [ICE](#ice) and [PDP](#pdp).
Ceterus paribus profiles are basically ICE curves, but for just one data point.
Therefore ICE plots are just multiple ceterus paribus profiles overlayed.
And PDP plots are just ceterus paribus profiled averaged across the data.

TODO: Draw with procreate an image and put  here with cp -> ice -> pdp

There is also a close relation to [counterfactual explanations](#counterfactuals).
Counterfactual explanations define a desired output (prediction) and then search for feature changes that achieve that desired outcome.
Ceterus Paribus are also "What-If" tools, but do the much simpler inverse and do changes in the features and observe what the outcome is.
You could actually use Ceterus Paribus Plots to search for counterfactual explanations that are just based on single feature changes.
Ceterus paribus are also related to a method from sensitivity analysis called one-at-a-time (OAT).

Ceterus paribus analysis is also a fix to some problems of attribution-based techniques like [SHAP](#shap), and to some degree also [LIME](#lime).
These attribution techniques are also for explaining individual predictions.
Each feature gets a value, and the values should sum up to the prediction (minus some intercept usually).
But a problem is that these attributions don't tell us at all how exactly the prediction changes when changing the feature.


Ceterus paribus are really one of the simplest tools there are in interpretability.
I love about them that they highlights how most of the model-agnostic methods work:
We get information out of the model by manipulating the input data and observing how the output changes.
Many methods get quite sophisticated about it, like Shapley values which bring in huge background of game theory and algorithms etc.. 

## Advantages

**Ceterus paribus is super simple to implement and understand.**
This makes them a great entry point for beginners, but also for communicating model-agnostic explainability to others, especially non-experts.
This is 

**This simple what-if plots can fix limitations of attribuion methods.**
Attribution-based methods like SHAP or LIME don't show how sensitive the prediction function is to local changes.
While LIME technically does, it has the neighborhood problem, which makes it difficult to see what local really means.
Ceterus paribus plots can complement attribution-based techniques and provide a complete picture when it comes to explaining individual predicitons.

**Ceterus paribus plots are flexible building blocks.**
They are building blocks for other interpretation methods, but you can also get creative in combining these lines across models, classes, hyperparameter settings, features, and so on to create a varied insight into the model.

## Disadvantages

**Ceterus paribus plots only show us one feature change at a time.**
While this simplicity is also a strength, it's also a limitation.
Of course you can go ahead and change two features, especially if it's one continuous and one binary, and plot them in the same plot.
But it's a more manual process.

As all model-agnostic methods, **intepretation suffers when features are correlated**.
When feature are correlated, not all parts of the curve are likely or might even be completey unrealistic.
This an be alleviated by e.g. restricting the range of the ceteris paribus plots to shorter ranges, at least for correlated features.
But this would also mean we need a model or procedure to tell us what these ranges are


## Software and Alternatives

The [ceterisParibus R package](https://cran.r-project.org/web/packages/ceterisParibus/index.html) implements Ceteris Paribus Profiles, which are What-If Plots for the entire feature range (as I also recommended to do in this chapter, which was actually inspired by this package).
The ceterisParibus method is also available in [Python](https://github.com/ModelOriented/pyCeterisParibus).


