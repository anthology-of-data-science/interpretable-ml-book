# About the Book {-}

Machine learning has great potential for improving products, processes and research.
But **computers usually do not explain their predictions** which is a barrier to the adoption of machine learning.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
The focus of the book is on model-agnostic methods for **interpreting black box models** such as feature importance and accumulated local effects, and explaining individual predictions with Shapley values and LIME.
In addition, the book presents methods specific to deep neural networks.

All interpretation methods are explained in depth and discussed critically.
How do they work under the hood?
What are their strengths and weaknesses?
How can their outputs be interpreted?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.


<!-- high-level view of books journey -->
TODO: shorten this starkly 

This book started as a side project when I was working as a statistician in clinical research.
I worked four days a week, and on my "day off" I worked on side projects.
Eventually, interpretable machine learning became one of my side projects.
At first I had no intention of writing a book.
Instead, I was simply interested in finding out more about interpretable machine learning and was looking for good resources to learn from.
Given the success of machine learning and the importance of interpretability, I expected that there would be tons of books and tutorials on this topic.
But I only found the relevant research papers and a few blog posts scattered around the internet, but nothing with a good overview.
No books, no tutorials, no overview papers, nothing.
This gap inspired me to start writing this book.
I ended up writing the book I wished was available when I began my study of interpretable machine learning.
My intention with this book was twofold: to learn for myself and to share this new knowledge with others.


<!-- Introduction to Author -->
**About the author:**
My name is Christoph Molnar, I'm a statistician and a machine learner.
My goal is to make machine learning interpretable.
I received my bachelor's and master's degree in statistics at the LMU Munich, Germany.
Most of my knowledge about machine learning was self-taught through online courses, competitions, side projects and professional activities.
My statistical background was an excellent basis for getting into machine learning, and especially for interpretability.
In statistics, a major focus is on building interpretable regression models.
After I finished my master's degree in statistics, I decided not to pursue a PhD, because I did not enjoy writing my master's thesis.
Writing just stressed me out too much.
So I took jobs as data scientist in a Fintech start-up and as statistician in clinical research.
After these three years in industry I started writing this book and a few months later I started a PhD in interpretable machine learning.
While working on this book, I rediscovered the joy of writing and it helped me to develop a passion for research.

TODO: include image
TODO: think about where to put about the author for print/ebook



Follow me on Twitter! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)

![](./images/by-nc-sa.png)

This book is licensed under the [CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/).



