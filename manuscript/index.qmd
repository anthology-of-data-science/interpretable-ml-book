# About the Book {-}

Machine learning is part of of our products, processes and research.
But **computers usually don't explain their predictions** which can cause many problems, ranging from trust issues to undectected problems.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
The focus of the book is on model-agnostic methods for **interpreting black box models** ranging from methods for explaining individual preditions, such as SHAP and LIME, to interpreting more general relations between features and prediction with permutation feature importance and accumulated local effects.
In addition, the book presents methods specific to deep neural networks.

All interpretation methods are explained in depth and discussed critically.
How do they work?
What are their strengths and weaknesses?
How to interpret them?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.

<!-- high-level view of books journey -->
This book began as a side project while I was working as a statistician in clinical research.
On my "day off," I explored topics that interested me, and interpretable machine learning eventually caught my focus.
Expecting plenty of resources on this important subject, I was surprised to find only scattered research papers and blog posts, with no comprehensive guide.
This motivated me to create the resource I wished existed -- a book to both deepen my own understanding and share insights on interpretable machine learning with others.
Today this book is a go-to resource for Interpretable Machine Learning.
It has been a reference to thousands of research papers, students messaged me that it was essential to their theses, and instructors use it in their classes, and data scientists in industry rely on it for their daily work and recommend it to their colleagues.

## Who this book is for

This book is for practitioners looking for an overview of techniques to make machine learning models more interpretable.
Itâ€™s also valuable for students, teachers, researchers, and anyone interested in the topic.
A basic understanding of machine learning and entry-level university math will help in following the theory and formulas, though the intuitive explanations at the start of each chapter should be accessible without them.

## About the author

Hi! My name is Christoph Molnar I write and teach about machine learning, specifically topics that go beyond merely predictive performance. 
I studied statistics, worked for a few years as a data scientist, did my PhD on interpretable machine learning, and now I'm a full-time writer.
I also [offer workshops](https://christophmolnar.com/workshops/) and [consulting](https://christophmolnar.com/consulting/).
To stay up to date with my work on machine learning, you can subscribe to my newsletter [Mindful Modeler](https://mindfulmodeler.substack.com/).


![](./images/by-nc-sa.png)

This book is licensed under the [CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/) license.



